# Quiz 2

## 2018 spring

### a

Let X1, X2, and X3 be independent random variables with the continuous uniform distribution over [0, 1]. Then P(X1 < X2 < X3) =


### b 

Let X and Y be two continuous random variables. Then
(i) E[XY ] = E[X]E[Y ]
(ii) E[X2 + Y 2] = E[X2] + E[Y 2]
(iii) fX+Y (x + y) = fX(x)fY (y)
j(iv) var(X + Y ) = var(X) + var(Y )

### c

Suppose X is uniformly distributed over [0, 4] and Y is uniformly distributed over [0, 1]. Assume
X and Y are independent. Let Z = X + Y . Then
(i) fZ(4.5) = 0
(ii) fZ(4.5) = 1/8
(iii) fZ(4.5) = 1/4
(iv) fZ(4.5) = 1/2

$\displaystyle (e^(-Î») * Î»^k) / k!$

### f

Suppose X and Y are Poisson random variables with parameters Î»1 and Î»2 respectively, where
X and Y are independent. Define W = X + Y , then
(i) W is Poisson with parameter min(Î»1, Î»2)
(ii) W is Poisson with parameter Î»1 + Î»2
(iii) W may not be Poisson but has mean equal to min(Î»1, Î»2)
(iv) W may not be Poisson but has mean equal to Î»1 + Î»2

* The Sum of Independent Normal Random Variables

### g

Let X be a random variable whose transform is given by $M_X(s) = (0.4 + 0.6e^s)^50$. Then
(i) P(X = 0) = P(X = 50)
(ii) P(X = 51) > 0
(iii) P(X = 0) = (0.4)50
(iv) P(X = 50) = 0.6

Solution: Note that $M_X(s)$ is the transform of a binomial random variable X with n = 50 trials and the probability of success p = 0.6. Thus, $P(X = 0) = 0.4^50.$ 

è¿™é“é¢˜ç›®ä½¿ç”¨äº†moment generating functionï¼Œæš‚æ—¶æ’¤ã€‚

### h

Let Xi, i = 1, 2, . . . be independent random variables all distributed according to the PDF $f_X(x) = \frac{x}{8}$ for 0 â‰¤ x â‰¤ 4. Let $S = \frac{1}{100} \sum_{i=1}^{100} X_i$. Then P(S > 3) is approximately equal 100 i=1
to
(i) 1 âˆ’ Î¦(5)
(ii) Î¦(5) 
(iii) $1 âˆ’ Î¦ \frac{5}{\sqrt{2}}$  
(iv) $ Î¦ \frac{5}{\sqrt{2}}$  

Solution: 
Let $ S = \frac{1}{100} \sum_{i = 1}^{100}Y_i $ where $Y_i$ is the random variable given by $Y_i$ = $X_1/100$. Since Yi are iid, the distribution of S is approximately
normal with mean E[S] and variance var(S).
3 âˆ’ E(S)
Thus, P(S > 3) = 1 âˆ’ P(S â‰¤ 3) â‰ˆ $1 âˆ’ Î¦(\frac{3 - E(s)}{\sqrt{var(s)}}) $. Now,

* è¿™é‡Œéœ€è¦ä½¿ç”¨CLTçš„ç»“è®ºï¼Œå°†sè½¬åŒ–æˆ Z(zæ˜¯ var(Z)=1  E[Z] = 0)ã€‚

### i
           
Let Xi, i = 1, 2, . . . be independent random variables all distributed according to the PDF f_X(x) = 1, 0 â‰¤ x â‰¤ 1. Define Y_n = X_1X_2X_3 . . . X_n, for some integer n. Then var(Yn) is equal to

solution: 

$\frac{1}{3^n} - \frac{1}{4^n} $

* è¦è®¤è¯†åˆ° E[XY] = E[X]E[Y]ï¼Œåœ¨Xå’ŒYä¸ºç‹¬ç«‹çš„å‰æä¸‹ã€‚

### Question 2: 

Each Mac book has a lifetime that is exponentially distributed with parameter Î».The lifetime of Mac books are independent of each other. Suppose you have two Mac books, which you begin using at the same time. Define T1 as the time of the first laptop failure and T2 as the time of the second laptop failure.

a. (4 pts) Compute fT1 (t1)
b. (5 pts) Let X = T2 âˆ’ T1. Compute fX|T1 (x|t1)
c. (5 pts) Is X independent of T1? Give a mathematical justification for your answer.
d. (8 pts) Compute fT2 (t2) and E[T2]
e. (5 pts) Now suppose you have 100 Mac books, and let Y be the time of the first laptop failure.

Find the best answer for P(Y < 0.01)

Your friend, Charlie, loves Mac books so much he buys S new Mac books every day! On any given day
S is equally likely to be 4 or 8, and all days are independent from each other. Let S100 be the number
of Mac books Charlie buys over the next 100 days.

f. (6 pts) Find the best approximation for P(S_100 â‰¤ 608). Express your final answer in terms of Î¦(.), the CDF of the standard normal.

Let $X = T_2 âˆ’ T_1$. Compute $f_{X|T_1} (x|t_1)$.

Solution: 

Conditioned on the time of the first mac book failure, the time until the other mac book fails is an exponential random variable by the memoryless property. The memoryless property tells us that regardless of the elapsed life time of the mac book, the time until failure has the same exponential CDF. Consequently,

$f_{X|T1 (x)} = Î»e^{âˆ’Î»x} \quad, x â‰¥ 0$.


b é¡¹ï¼Œéœ€è¦è¿ç”¨æŒ‡æ•°åˆ†å¸ƒçš„memorylessçš„æ€§è´¨ã€‚åœ¨æœ¬é¢˜ä¸­æ˜¯å¦‚ä¸‹çš„è¡¨è¾¾å¼ï¼š

$\displaystyle P_{X \mid T_1}(x \mid t_1) = P_{T_2 \mid T_1}(x \mid t_1 ) = P_{T_2}(x) $

æ›´åŠ ç›´è§‚ï¼š$\displaystyle P(T_2 = T_1 + x \mid T_1 = t_1) = P_{T_2}(x)$
ä¸ç¯æ³¡çš„ä¾‹å­æ‰€ä¸åŒçš„æ˜¯æ­¤å¤„å°†å·²ç»â€œä½¿ç”¨äº†çš„æ—¶é—´è®¾ç½®æˆäº†ä¸€ä¸ªéšæœºå˜é‡â€ã€‚

c é¡¹ï¼Œå¯¹äºç‹¬ç«‹çš„å®šä¹‰ï¼šP(A,B) = P(A)P(B)ï¼Œæ­¤å¤„ä½¿ç”¨å®šä¹‰æ¥åˆ¤å®šã€‚

$ f_{X, T_1}(x, t_1) = f_{T_1}(t_1)f_{X \mid T_1}(x \mid t_1) $


$ f_{X \mid T_1}(x \mid t_1) = \lambda e^{-\lambda x} $
åœ¨T_1çš„æ¡ä»¶ä¸‹ï¼Œå¯ä»¥ç†è§£ä¸ºæ¨¡å‹å˜åŒ–æˆäº†æ‰€ç†Ÿæ‚‰çš„æ ·ä¾‹ä¸­çš„æ ·å­ï¼Œå˜æˆäº†ä¸€ä¸ªå•çº¯çš„æŒ‡æ•°åˆ†å¸ƒã€‚

d é¡¹ï¼Œ
$ f_{X \mid T_1}(x \mid t_1) = f_{X}(x) $ è¿™ä¸ªå°±å¾ˆç±»ä¼¼T_2å·²ç»ä½¿ç”¨äº†t_1æ—¶é—´ï¼Œç»§ç»­ä½¿ç”¨xæ—¶é—´ã€‚ä½†æ˜¯ä¸ç¬”è®°ä¸­äº†æ ·ä¾‹å¹¶ä¸ç›¸åŒï¼šä»–åªæ˜¯ä¸€ä¸ªç¯æ³¡ï¼Œè€Œä¸”å°†æ€»æ—¶é—´è®¾ç½®ä¸ºTï¼Œä½¿ç”¨äº†ä¸€ä¸ªå¸¸é‡t_1ï¼Œå‰©ä½™ä½¿ç”¨çš„æ—¶é—´è®¾ç½®ä¸ºXã€‚ç„¶åå¾—å‡ºäº†ç»“è®ºï¼š$\displaystyle P(X = x \mid T > t_1 ) \quad , T = t_1 + x \quad, P(T = x + t_1) $
ç”±æ­¤å¯ä»¥å¾—å‡º: $\displaystyle P(X = x \mid T > t) = P(T = x) $

è¿™ä¸ªæˆ‘æ˜¯ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼š$\displaystyle f_X(x) = \lambda e^{- \lambda x}$
è™½ç„¶æˆ‘å¯ä»¥å¾—åˆ°$\displaystyle f_{X \mid T_1}(x \mid t_1)$ï¼Œåœ¨æ¡ä»¶ä¸‹ä»–æ˜¯ç­‰æ•ˆäº ğŸ’¡æ¨¡å‹ï¼Œä½†æ˜¯ä¸ºä»€ä¹ˆf_X(x)ä¹Ÿä¼šæ˜¯æŒ‡æ•°åˆ†å¸ƒï¼Ÿ

e é¡¹ï¼Œæ€è·¯ä¸aæ˜¯ä¸€æ ·çš„ã€‚


Your friend, Charlie, loves Mac books so much he buys S new Mac books every day! On any given day S is equally likely to be 4 or 8, and all days are independent from each other. Let S100 be the number of Mac books Charlie buys over the next 100 days.

f. (6 pts) Find the best approximation for P(S100 â‰¤ 608). Express your final answer in terms of
Î¦( ), Â· the CDF of the standard normal.

Solution
Using the De Moivre - Laplace Approximation to the Binomial, and noting that the step size between values that S can take on is 4,

ä½¿ç”¨CLTçš„æ€æƒ³ï¼Œä½†æ˜¯è¿™é“é¢˜ç›®é¢å¤–ä½¿ç”¨äº†De Moivre - Laplaceï¼Œæš‚æ—¶æ²¡å­¦ã€‚

$p(S_100 \leq 608) = Î¦(\frac{(608 + 2 - 100 * 6)}{ \sqrt{100 * 4}}) $


### Question 3: 

Question 3: Saif is a well intentioned though slightly indecisive fellow. Every morning he flips a coin to decide where to go. If the coin is heads he drives to the mall, if it comes up tails he volunteers at the local shelter. Saifâ€™s coin is not necessarily fair, rather it possesses a probability of heads equal to q. We do not know q, but we do know it is well-modeled by a random variable Q where the density of Q is

$$
f_Q(q)=
\begin{cases}
2q \quad for 0 \leq q \leq 1 \\
0 \quad otherwise    
\end{cases}
$$

Assume conditioned on Q each coin flip is independent. Note parts a, b, c, and {d, e} may be answered independent of each other.
a. (4 pts) Whatâ€™s the probability that Saif goes to the local shelter if he flips the coin once?

In an attempt to promote virtuous behavior, Saifâ€™s father offers to pay him $4 every day he volunteers at the local shelter. Define X as Saifâ€™s payout if he flips the coin every morning for the next 30 days.

b. (6 pts) Find var(X)

Let event B be that Saif goes to the local shelter at least once in k days.
c. (6 pts) Find the conditional density of Q given B, fQ B(q) |
While shopping at the mall, Saif gets a call from his sister Mais. They agree to meet at the Coco Cabana Court yard at exactly 1:30PM. Unfortunately Mais arrives Z minutes late, where Z is a continuous uniform random variable from zero to 10 minutes. Saif is furious that Mais has kept him waiting, and demands Mais pay him R dollars where R = exp(Z + 2).
    
d. (6 pts) Find Saifâ€™s expected payout, E[R]

e. (6 pts) Find the density of Saifâ€™s payout, fR(r)


a é¡¹ï¼Œä»¤æˆ‘æ„Ÿåˆ°è¿·æƒ‘çš„æ˜¯
$$
f_{X,Y}(x,y) = f_{Y}(y)f_{X \mid Y}(x \mid y) \\ \\ 
f_X(x) = \int f_Y(y)f_{X \mid Y}(x \mid y) dy
$$

å†™å‡ºæ¥åæ¸…æ™°å¾ˆå¤šï¼Œå®é™…ä¸Š$\displaystyle f_{X\mid Y}(x \mid y)f_Y(Y)=f_{X,Y}(x,y)$ï¼Œåœ¨å°†å…¶ä½œç§¯åˆ†å®é™…ä¸Šä»–å°±æ˜¯è¿ç”¨äº†joint PDF è®¡ç®—margin PDF.

$\displaystyle P(X)= P( X=x\mid Q=q )P_Q(q)$

$\displaystyle \int_0^1 (1-q) f_q (q)dq$

b é¡¹ï¼Œæ€è·¯çš„å…³é”®ç‚¹æ˜¯ä½¿ç”¨total variance . $\displaystyle var(X)= E[var(X\mid Y)]+var(E[X\mid Y])$ è¿™é‡Œæœ‰ä¸€ä¸ªå…³é”®ç‚¹ï¼š
1. è¿™æ˜¯æˆ‘çš„ä½¿ç”¨total varianceçš„æ€è·¯ï¼š$var(X) = var(Y_1+Y_2+Y_3+ ...+ Y_30 = 30 var(Y) = 30 E[var(Y \mid Q)] + var(E[Y\mid Q])$
2. è¿™æ˜¯ç­”æ¡ˆçš„æ€è·¯: $var(X) = E[var(Y_1+Y_2+Y_3+ ... + Y_30 \mid Q)] + var(E[Y_1+Y_2+Y_3+ ... +Y_1 \mid Q])$

ä»¥ä¸‹å¼•ç”¨chatgptçš„å›ç­”ï¼š
>å¯¹äºæ–¹å·®çš„ç‹¬ç«‹æ€§ï¼Œç¡®å®å½“éšæœºå˜é‡æ˜¯ç›¸äº’ç‹¬ç«‹æ—¶ï¼Œå®ƒä»¬çš„æ–¹å·®ä¹‹å’Œç­‰äºå„è‡ªæ–¹å·®ä¹‹å’Œã€‚ç„¶è€Œï¼Œåœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œ$Y_i$ ä¸æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä¾èµ–äºç›¸åŒçš„éšæœºå˜é‡ $Q$ã€‚æ¯ä¸ª $Y_i$ éƒ½æ˜¯åœ¨ç»™å®š $Q$ çš„æƒ…å†µä¸‹ç‹¬ç«‹çš„ï¼Œä½†å®ƒä»¬ä¹‹é—´å¹¶ä¸ç‹¬ç«‹ã€‚
å…·ä½“æ¥è¯´ï¼Œæ–¹å·®çš„ç‹¬ç«‹æ€§æ˜¯æŒ‡å¦‚æœ $X_1, X_2, \ldots, X_n$ æ˜¯ç›¸äº’ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œåˆ™ $\text{var}(X_1 + X_2 + \ldots + X_n) = \text{var}(X_1) + \text{var}(X_2) + \ldots + \text{var}(X_n)$ã€‚åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œ$Y_1, Y_2, \ldots, Y_{30}$ éƒ½ä¾èµ–äºç›¸åŒçš„éšæœºå˜é‡ $Q$ï¼Œå› æ­¤å®ƒä»¬ä¹‹é—´å¹¶ä¸æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚å› æ­¤ï¼Œä¸èƒ½ç®€å•åœ°å°†å®ƒä»¬çš„æ–¹å·®ç›¸åŠ ã€‚

c é¡¹ï¼Œè®¡ç®—$\displaystyle f_{Q \mid B}(q)$:

ç±»æ¯”ç¦»æ•£éšæœºå˜é‡å¯ä»¥å¾—åˆ°ï¼š$\displaystyle P_{Q \mid B}(q) = \frac{P(q \leq Q \leq q + \delta , B)}{P(B)}$

$\displaystyle P(B)=\sum_Q P_Q(q)P(B \mid Q=q)$ï¼Œè¿™é‡Œä½¿ç”¨çš„æ€æƒ³æ˜¯ï¼štotal probabilityã€‚æ‰€ä¸åŒçš„æ˜¯Qæ˜¯è¿ç»­éšæœºå˜é‡ã€‚
$\displaystyle P(B) =\sum_Q f_Q(q)\times \delta \times P(B \mid Q=q)$
å†™æˆç§¯åˆ†çš„å½¢å¼ï¼š

$\displaystyle P(B) =\int_{-\infin}^{+\infin}P(B \mid Q=q)f_Q(q)dq$

åˆ†å­éƒ¨åˆ†


$\displaystyle P(q \leq Q \leq q + \delta, B) = P_Q(q)P_{B \mid Q}(B \mid q) = 
f_Q(q)\delta P_{B \mid Q}(B \mid q)$

ç”±æ­¤å¯ä»¥å¾—åˆ°ï¼š

$$
P_{Q \mid B}(q) = \frac{f_Q(q)\delta P_{B \mid Q}(B \mid q)}{\int_{-\infin}^{+\infin}P(B \mid Q=q)f_Q(q)dq} \\
f_{Q \mid B}(q)\delta  = \frac{f_Q(q)\delta P_{B \mid Q}(B \mid q)}{\int_{-\infin}^{+\infin}P(B \mid Q=q)f_Q(q)dq}\\
f_{Q \mid B}(q)  = \frac{f_Q(q) P_{B \mid Q}(B \mid q)}{\int_{-\infin}^{+\infin}P(B \mid Q=q)f_Q(q)dq}
$$

## 2009


### Problem 3. (10 points)

For the following questions, mark the correct answer. If you get it right, you receive 5 points for that question.
You receive no credit if you get it wrong. A justification is not required and will not be taken into account.
Let X and Y be continuous random variables. Let N be a discrete random variable.

a. (5 points) The quantity E[X | Y ] is always:

(i) A number.

(ii) A discrete random variable.

(iii) A continuous random variable.

(iv) Not enough informa]b
tion to choose between (i)-(iii).


b. (5 points) The quantity E[ E[X | Y, N] | N] is always:

(i) A number.

(ii) A discrete random variable.

(iii) A continuous random variable.

(iv) Not enough information to choose between (i)-(iii).


å°†æ¡ä»¶æœŸæœ›è§†ä½œéšæœºå˜é‡ï¼šE[X]æ˜¯ä¸€ä¸ªnumberï¼Œ$\displaystyle E[X\mid Y]$æ˜¯å…³äºYçš„å‡½æ•°ï¼š$g(Y)=g(y), if Y=y$

åœ¨è®¨è®ºaï¼Œbé¡¹æ—¶ï¼Œè¦æ ¹æ®Xå’ŒYå’ŒNæ˜¯å¦æ˜¯ç‹¬ç«‹åˆ’åˆ†æƒ…å†µï¼š

1. $E[X\mid Y]=E[X] \quad if \  X \ and \ Y \ is \ independent$
2. $E[X\mid Y]=g(Y) \quad if \  X \ and \ Y \ is \ independent$


## Problem 4. (25 points)

The probability of obtaining heads in a single flip of a certain coin is itself a random variable, denoted by Q,

which is uniformly distributed in [0, 1]. Let X = 1 if the coin flip results in heads, and X = 0 if the coin flip

results in tails.

(a) 
(i) (5 points) Find the mean of X.
(ii) (5 points) Find the variance of X.

(b) (7 points) Find the covariance of X and Q.

(c) (8 points) Find the conditional PDF of Q given that X = 1.


b é¡¹ï¼Œè®¡ç®—åæ–¹å·®ï¼š$\displaystyle cov(X,Q)=E[XQ] -E[X]E[Q]$,åœ¨è®¡ç®—E[XQ]æ—¶éœ€è¦ç”¨åˆ°æ¡ä»¶æœŸæœ›çš„æ€æƒ³ï¼š

1. æ¡ä»¶çš„æ€æƒ³å°±æ˜¯å°†ä¸€ä¸ªå¤æ‚çš„è®¡ç®—ç¼©å°ä¸€å®šçš„èŒƒå›´æ¥è®¡ç®—ï¼Œè¿™æ˜¯ä¸€ç§åˆ†è€Œæ²»ä¹‹çš„ç­–ç•¥ã€‚
2. æœŸæœ›çš„åˆ†æ²»æ€æƒ³çš„å…·ä½“ä½“ç°å°±æ˜¯ä½¿ç”¨ï¼štotal expection å’Œ iteration rule.

$\displaystyle E[XQ]= E[E[XQ \mid Q]] = \sum_X \sum_Q xqP_{X,Q \mid Q}(x,q)$

$\displaystyle P_{X,Q \mid Q}(x,q)=P_{Q \mid Q}(q) P_{X \mid Q ,Q}(x)=P_{Q}(q)P_{X \mid Q}(x)$

åˆ©ç”¨è¿™ä¸¤ä¸ªå¼å­å¯ä»¥ç”¨å®šä¹‰è¡¨ç¤ºå‡º$\displaystyle E[XQ \mid Q] \to E[Q]E[X \mid Q]$

$\displaystyle E[Q] = q$ã€‚

### Problem 5

Let X and Y be independent continuous random variables with marginal PDFs fX and fY , and marginal
CDFs FX and FY , respectively. Let S = min{X, Y }, L = max{X, Y }.

(a) (7 points) If X and Y are standard normal, find the probability that S â‰¥ 1.

(b) (7 points) Fix some s and Â£ with s â‰¤ Â£. Give a formula for P(s â‰¤ S and L â‰¤ Â£)
involving FX and FY , and no integrals.

(c) (7 points) Assume that s â‰¤ s + Î´ â‰¤ Â£. Give a formula for
P(s â‰¤ S â‰¤ s + Î´, Â£ â‰¤ L â‰¤ Â£ + Î´), as an integral involving fX and fY .
 


b é¡¹ï¼Œè¦æ³¨æ„è½¬æ¢æˆXå’ŒYçš„è¡¨è¾¾å¼ï¼š$\displaystyle P(s \leq X, s\leq Y \ and \ X \leq l, Y \leq l)$

bçš„ç­”æ¡ˆåº”è¯¥æœ‰é—®é¢˜ï¼Œåº”è¯¥Xå’ŒYçš„è¡¨è¾¾å¼æ˜¯ä¸€è‡´çš„ã€‚

c é¡¹ï¼Œåˆ†æƒ…å†µè®¨è®ºï¼šX > Y and Y > X

## 2010

### Problem 1. (80 points) In this problem:

(i) X is a (continuous) uniform random variable on [0, 4].
(ii) Y is an exponential random variable, independent from X, with parameter Î» = 2.

1. (10 points) Find the mean and variance of X âˆ’ 3Y .
2. (10 points) Find the probability that Y â‰¥ X.
(Let c be the answer to this question.)
3. (10 points) Find the conditional joint PDF of X and Y , given that the event Y â‰¥ X has
occurred.(You may express your answer in terms of the constant c from the previous part.)
4. (10 points) Find the PDF of Z = X + Y .
5. (10 points) Provide a fully labeled sketch of the conditional PDF of Z given that Y = 3.
6. (10 points) Find E[Z | Y = y] and E[Z | Y ].
7. (10 points) Find the joint PDF fZ,Y of Z and Y .
8. (10 points) A random variable W is defined as follows. We toss a fair coin (independent of Y ).
If the result is â€œheadsâ€, we let W = Y ; if it is tails, we let W = 2 + Y . Find the probability of
â€œheadsâ€ given that W = 3.

2 é¡¹ï¼Œ è§£å†³çš„æ€è·¯æ˜¯ total probabilityã€‚åªä¸è¿‡é¢˜ç›®çš„è¡¨è¿°ä¸å¤ªç¬¦åˆä¹ æƒ¯ã€‚å°†$\displaystyle Y \geq X$è®¾ä¸ºäº‹ä»¶Aï¼Œé‚£ä¹ˆå¯ä»¥å°†å…¶è¡¨è¿°ä¸º$\displaystyle P(A) = \sum _X P(A \mid X)P(x)$
æŒ‡æ•°åˆ†å¸ƒ $\displaystyle F(Y \geq y)= e^{-\lambda y}$

3 é¡¹ï¼Œè€ƒè¯•æ€è·¯ï¼šå½“éœ€è¦è®¡ç®—æ¡ä»¶PDFï¼Œé¦–å…ˆæ€è€ƒbayesã€‚

æ‰¿æ¥2çš„å™è¿°å†åŠ ä¸Šä½¿ç”¨Bayes $\displaystyle f_{X,Y \mid A}(x,y) = \frac{f_{X,Y}(x,y)}{P(A)}$ã€‚è¿™é‡Œå­˜åœ¨ä¸€ä¸ªè¯¯åŒºï¼Œå°†è”åˆçš„å¯†åº¦è¡¨è¿°ä¸ºï¼š$\displaystyle f_{X,Y,A}(x,y,A)$ã€‚
å‰è€…æ˜¯å°†Aå½“æˆæ˜¯ä¸€ä¸ªäº‹ä»¶ï¼Œåè€…æ˜¯è®¤ä¸ºä»–æ˜¯ä¸€ä¸ªéšæœºå˜é‡ã€‚æ­¤å¤„å¼•ç”¨chatgpt3.5ï¼š

>äº‹ä»¶è¡¨è¿°çš„æ˜¯æ ·æœ¬ç©ºé—´å¯èƒ½çš„ç»“æœï¼Œéšæœºå˜é‡æ˜¯å°†æ ·æœ¬ç©ºé—´æ˜ å°„å€¼çš„æ˜ å°„ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œäº‹ä»¶æ˜¯æ ·æœ¬ç©ºé—´çš„ç»“æœï¼Œéšæœºå˜é‡æœ¬èº«ä»£è¡¨çš„å°±æ˜¯æ ·æœ¬ç©ºé—´ï¼Œä¸è¿‡ä½¿ç”¨æ˜ å°„çš„å½¢å¼ã€‚

4 é¡¹ï¼Œç­”æ¡ˆç»™å‡ºäº†å¦‚ä¸‹çš„å½¢å¼ï¼Œç»è¿‡äº†å˜æ¢ï¼Œè®²é“ç†ä¸å¤ªèƒ½çœ‹æ‡‚è¿™ç§å½¢å¼ï¼š$\displaystyle f_Z(z) = \int _{Max(0, z-4)} ^z \frac{1}{4}2e^{-2t}dt$

å‰é¢çš„æ€è·¯å°±æ˜¯åˆ©ç”¨å·ç§¯çš„å…¬å¼æ¥è®¡ç®—ï¼Œä½†æ­¤å¤„éœ€è¦æ³¨æ„ï¼Œç”±äºXå’ŒYçš„å®šä¹‰åŸŸéƒ½ä¸æ˜¯å¯¹åº”è¿™æ•´ä¸ªæ•°è½´ï¼Œæ‰€è¦è¦ç¡®ä¿zçš„èŒƒå›´æ˜¯åœ¨æœ‰æ•ˆçš„èŒƒå›´ä¸­(å› ä¸ºzæ¥æºäºXå’ŒY)

åˆ†ç±»è®¨è®º(è¦åŒæ—¶èƒ½å¤Ÿæ»¡è¶³Xå’ŒY)ï¼š
1. $\displaystyle z \geq 4$,è¿™ç§æƒ…å†µä¸‹ï¼Œ $y= z-x\geq 0$ä¸€å®šæˆç«‹ï¼Œæ‰€æœ‰xçš„èŒƒå›´[0,4]
2. $\displaystyle 0 \leq z \leq 4$,è¿™ç§æƒ…å†µä¸‹ï¼Œ$y= z-x\geq 0, \quad x\leq z$,æ‰€ä»¥æ­¤æ—¶ xçš„èŒƒå›´[0,z]

åœ¨è¿™é“é¢˜ä¸­æˆ‘é‡æ–°æ€è€ƒäº†total probability åœ¨è¿ç»­å’Œç¦»æ•£éšæœºå˜é‡ä¹‹ä¸­çš„è”ç³»ï¼š

å¯¹äºç¦»æ•£éšæœºå˜é‡æ¥è¯´ï¼Œæ±‚ä¸€ä¸ªäº‹ä»¶çš„æ¦‚ç‡ç›´æ¥ä½¿ç”¨total probabilityï¼Œä»–ç›´æ¥è¡¨è¿°æˆï¼š$\displaystyle P_X(x)=P_{X \mid Y}(X \mid y=y_1)P_Y(y)+P_{X \mid Y}(X \mid y=y_2)P_Y(y)+P_{X \mid Y}(X \mid y=y_3)P_Y(y)+ \dots +P_{X \mid Y}(X \mid y=y_n)P_Y(y) = \sum_Y P_{X\mid Y}(x \mid y)P_Y(y)$

å¯¹äºè¿ç»­éšæœºå˜é‡æ¥è¯´ï¼Œtotal probabilityçš„æœ€ä¸Šå±‚çš„æ€æƒ³æ˜¯ï¼šjoint PDFæ±‚å–margin PDFã€‚
$\displaystyle f_X(x)=\int_{-\infin}^{\infin}f_{X,Y}(x,y)dy$ï¼Œé€šè¿‡ä¹˜æ³•æ³•åˆ™å°†å…¶è½¬æ¢æˆï¼š
$\displaystyle f_X(x)=\int_{-\infin}^{\infin}f_{X\mid Y}(x\mid y)f_Y(y)dy$,è¿™æœ€ç»ˆå¾—åˆ°äº†è´´åˆç¦»æ•£éšæœºå˜é‡çš„total probabiliy çš„å½¢å¼ï¼Œä¹Ÿå°±æ˜¯è¿ç»­éšæœºå˜é‡çš„è¡¨è¿°å½¢å¼ã€‚

æ¯”è¾ƒè¿™ä¸¤è€…çš„å½¢å¼ï¼Œç§¯åˆ†å·å¯¹åº”ç€æ±‚å’Œå·ï¼Œå†å°†PDFé€šè¿‡ä¹˜ä¸Šzçš„å˜åŒ–é‡ï¼Œç”¨$\delta$è¡¨ç¤ºï¼Œå°±å¯ä»¥çœ‹åˆ°ä¸¤è€…åœ¨æ•°å­¦è¡¨è¾¾ä¸Šçš„ä¸€ã€‚

ä»¥ä¸‹æ˜¯å¤§è‡´çš„ç»“æ„:

discrete: $\displaystyle P_Y(y)=\sum_X P_{X \mid Y}(x\mid y)P_{X}(x)$

discrete -> continuous: $\displaystyle f_Y(y) \epsilon=\sum_X f_{X \mid Y}(x\mid y)\epsilon f_{X}(x)\delta$

continuous: 
$\displaystyle f_Y(y) =f_{X \mid Y}(x\mid y) f_{X}(x)$ 

or 

$\displaystyle f_Y(y) =\int _x f_{X \mid Y}(x\mid y)f_{X}(x)dx$

8 é¡¹ï¼Œæ€è·¯æ˜¯ä½¿ç”¨Bayesã€‚

è¿™é‡Œå‡ºç°äº†ä¸€ä¸ªè¿·æƒ‘ç‚¹ï¼šå½“å­˜åœ¨è¿ç»­å˜é‡åœ¨Bayesçš„è¡¨è¾¾å¼ä¸­ï¼Œè€Œè¦æ¨æ–­çš„éšæœºå˜é‡æ˜¯ç¦»æ•£çš„ï¼Œé‚£æˆ‘åº”è¯¥æ€ä¹ˆè¡¨ç¤ºè¿ç»­éšæœºå˜é‡åœ¨æŸä¸€ä¸ªç‚¹ä¸Šçš„æ¦‚ç‡ï¼Œè¿™æ˜¯ä¸ºé›¶ã€‚

äº‹å®ä¸Šï¼Œè¿ç»­çš„éƒ¨åˆ†æ˜¯ä½¿ç”¨PDFå’Œ\deltaçš„ä¹˜ç§¯è¡¨ç¤ºï¼Œä½†æ˜¯æ‰€æœ‰çš„è¿ç»­éƒ¨åˆ†æœ€åéƒ½ä¼šå°†\deltaå‰Šæ‰ã€‚

### Problem 2. (30 points)

Let X, X1, X2, . . . be independent normal random variables with mean 0
and variance 9. Let N be a positive integer random variable with E[N] = 2 and $E[N^2] = 5. $We assume that the random variables N, X, X1, X2, . . . are independent. Let $S = \sum_{i=1}^N X_i$.

1. (10 points) If Î´ is a small positive number, we have P(1 â‰¤ |X| â‰¤ 1 +Î´) â‰ˆ Î±Î´, for some constant
Î±. Find the value of Î±.
2. (10 points) Find the variance of S.
3. (5 points) Are N and S uncorrelated? Justify your answer.
4. (5 points) Are N and S independent? Justify your answer.

2 é¡¹ï¼Œè®¡ç®—æ–¹å·®å’ŒæœŸæœ›ä½¿ç”¨å®šä¹‰(æ–¹å·®é¢å¤–æœ‰ç®€ä¾¿å½¢å¼è®¡ç®—)è¾ƒä¸ºå›°éš¾æ—¶ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨æ¡ä»¶æœŸæœ›(iterated expection $E[X \mid Y]$)æˆ–è€…æ¡ä»¶æ–¹å·®($var(X_1) = E[var(X_1 | Y)] + var(E[X_1 \mid Y])$)

3 é¡¹ï¼Œè®¡ç®— ç›¸å…³æ€§å¯ä»¥ä½¿ç”¨åæ–¹å·®æˆ–è€…æ¡ä»¶ç³»æ•°çš„å®šä¹‰è®¡ç®—ã€‚

* åæ–¹å·®è®¡ç®—çš„ç®€ä¾¿å½¢å¼ï¼š$\displaystyle cov(X,Y)=E[XY]-E[X]E[Y]$
* æœŸæœ›çš„æ€§è´¨ï¼š$E[X + Y] = E[X]+E[Y]$ï¼Œè¿™ä¸ªæ€§è´¨æ˜¯ä¸éœ€è¦è¦æ±‚ç‹¬ç«‹çš„ï¼Œå› ä¸ºé‡‡ç”¨å®šä¹‰ä¼šå¾—åˆ°å¦‚ä¸‹çš„å¼å­ï¼š$\displaystyle \sum_X \sum_Y XP_{X,Y}(x,y)+\sum_X \sum_Y YP_{X,Y}(x,y)$
* $var(X_1 + X_2)= var(X_1) + var(X_2) + cov(X_1,X_2)$ å¦‚æœX_1 å’Œ X_2 æ˜¯ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆcov(X_1, X_2)å°±æ˜¯0ï¼Œvar(X_1 + X_2)= var(X_1) + var(X_2)

4 é¡¹è¯æ˜Så’ŒNçš„ç›¸å…³æ€§ï¼š

* ç›¸å…³æ€§è¿™è¯æ˜ä½¿ç”¨å®šä¹‰ï¼šf_S(s)=f_{S \mid N}(S \mid N)
* è¿™é“é¢˜ç›®åˆ©ç”¨ï¼švar(S) != var(S | N),æ¥è¯æ˜ f_S(s)=f_{S \mid N}(s \mid n).å› ä¸ºæ–¹å·®çš„è®¡ç®—ä¸éšæœºå˜é‡æœ¬èº«çš„åˆ†å¸ƒæœ‰å…³ã€‚
* Sè¢«è®¤ä¸ºæ˜¯æ­£æ€åˆ†å¸ƒ,åŸå› æ˜¯ CLT(chatgptè¯´çš„)ã€‚


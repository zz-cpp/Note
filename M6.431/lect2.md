# Unit 2: Conditioning and independence

## Lec. 2: Conditioning and Bayes' rule

### 1.Overfiew

å¦‚æœè®©ä½ åœ¨æŸä¸€ä¸ªåŸé•‡çš„æˆ·ç±ç³»ç»Ÿä¸­éšæœºé€‰æ‹©ä¸€ä¸ªäººï¼Œä»–çš„å¹´é¾„æ˜¯18å²ä»¥ä¸‹çš„æ¦‚ç‡å¤§æ¦‚æ˜¯25%ï¼ˆæ¥è‡ªäºç»Ÿè®¡å­¦ 18å²ä»¥ä¸‹äººå£/æ‰€æœ‰äººå£ï¼‰ã€‚ä½†å¦‚æœæ­¤æ—¶å‘Šè¯‰ä½ è¿™ä¸ªäººå·²ç»ç»“å©šäº†ï¼Œé‚£ä¹ˆ25%çš„æ¦‚ç‡å°±ä¸å†æœ‰æ„ä¹‰ï¼Œåº”ä¸ºæˆ‘ä»¬çŸ¥é“ä¸€éƒ¨åˆ†æƒ…å†µå°±ä¸å¯èƒ½ï¼ˆä½ çŸ¥é“13ä»¥ä¸‹ä¸å¯èƒ½ç»“å©šï¼‰ã€‚
å½“è·å–æ–°çš„çŸ¥è¯†å’Œä¿¡æ¯æ—¶ï¼Œæ¦‚ç‡ä¼šå‘ç”Ÿæ”¹å˜ã€‚
ä¸»çº¿ï¼š

* conditional probability
* tools:
      1. Mutipilication rule
      2. Total probability theorm
      3. Bayes' rule(-> inference)
**å…¶ä¸­Bayes's ruleæ˜¯å°†å…¶ä»–çš„è¡¥å……ä¿¡æ¯æ·»åŠ åˆ°æ¦‚ç‡æ¨¡å‹çš„ç³»ç»Ÿæ€§æ–¹æ³•ã€‚**

### 2. Conditional probabilities

æ¡ä»¶æ¦‚ç‡æ˜¯ä¸ä¿®è®¢åçš„æ¨¡å‹ç›¸å…³çš„æ¦‚ç‡ï¼Œè¯¥æ¨¡å‹è€ƒè™‘äº†å…³äºæ¦‚ç‡å®éªŒç»“æœçš„ä¸€äº›é™„åŠ ä¿¡æ¯ã€‚

![](./ref/condition1.png)

å¦‚å›¾æ‰€ç¤ºï¼Œä½¿ç”¨discreate uniform law $p(A) = \frac{5}{12}, p(B) = \frac{6}{12}$

å‡è®¾å‘ç”Ÿçš„äº‹ä»¶æ˜¯Bï¼Œåˆ™æ­¤æ—¶Bä»¥å¤–çš„äº‹ä»¶å°±ä¸å¯èƒ½åœ¨å‘ç”Ÿï¼Œæ¦‚ç‡ä¸º0,åœ¨å›¾ä¸­çœç•¥ä¹‹å

![](ref/lect2/condition2.png)

æ­¤æ—¶$\displaystyle P(A|B)= \frac{2}{6}, P(B|B) = 1 $
å…¶ä¸­P(A|B)æŒ‡çš„æ˜¯åœ¨äº‹ä»¶Bå‘ç”Ÿæ—¶ï¼Œäº‹ä»¶Aå‘ç”Ÿçš„æ¦‚ç‡ã€‚å› ä¸ºå·²ç»ç¡®å®šå‘ç”Ÿçš„æ˜¯äº‹ä»¶Bï¼Œæ‰€ä»¥åœ¨Bå‘ç”Ÿæ—¶ï¼Œäº‹ä»¶Bå‘ç”Ÿçš„æ¦‚ç‡æ˜¯1ã€‚

#### condition probability defination

$\displaystyle P(A|B) = \frac{P(A \cap B)}{P(B)}$
åœ¨äº‹ä»¶Bå‘ç”Ÿçš„å‰æä¸‹ï¼Œäº‹ä»¶Açš„æ¦‚ç‡ã€‚

* å› ä¸ºä¸èƒ½é™¤ä»¥0,æ‰€ä»¥P(B) > 0
* è¿™æ˜¯ä¸€ä¸ªå®šä¹‰å¼ï¼Œæ‰€ä»¥ä¸å­˜åœ¨æ˜¯å¦æ­£ç¡®çš„è¯´æ³•ï¼Œä»–å°±æ˜¯å¦‚æ­¤å®šä¹‰çš„ã€‚

a problem

If $\varOmega$  is finite and we have a discrete uniform probability law, and if $ B \neq \empty $ , then the conditional probability law on $\varOmega$ , given that B  occurred, $ \varOmega$ is also discrete uniform.

è§£ï¼š
å‡è®¾åœ¨Bå·²ç»å‘ç”Ÿçš„æƒ…å†µä¸‹ï¼Œå¤„Bä»¥å¤–çš„æ¦‚ç‡éƒ½æ˜¯0,é‚£ä¹ˆå¯¹äºæ ·æœ¬ç©ºé—´ $\omega$ æ¥è¯´,æ¯ä¸ªå¯èƒ½çš„å–å€¼åœ¨æ ·æœ¬ç©ºé—´ä¸­ä¸å¯èƒ½å…·æœ‰ç›¸åŒçš„æ¦‚ï¼ˆç‡å¯¹äºBå†…éƒ¨çš„å–å€¼æ˜¯ç­‰æ¦‚ç‡çš„ï¼Œä½†æ˜¯å¯¹äºBå¤–éƒ¨çš„å°±ä¸å¯èƒ½æ˜¯ç­‰æ¦‚ç‡ï¼š0ï¼‰,æ‰€ä»¥åœ¨ç¡®å®šBå·²ç»å‘ç”Ÿçš„æƒ…å†µä¸‹ï¼Œæ ·æœ¬ \omega $ çš„æ¯ä¸€ä¸ªå–å€¼ä¸å¯èƒ½æ˜¯ç­‰æ¦‚ç‡ã€‚

* "Discrete uniform probability law"æŒ‡çš„æ˜¯ç¦»æ•£å‡åŒ€æ¦‚ç‡åˆ†å¸ƒã€‚

#### A die roll example

ä¸€ä¸ªå››é¢çš„è‰²å­ï¼Œæ¯ä¸€é¢éƒ½æ˜¯ç­‰å¯èƒ½æ€§è´¨

![](ref/lect2/roll_example1.png)

* äº‹ä»¶Bæ˜¯ï¼šmin(x,y) = 2; Mæ˜¯max(x,y)

å¦‚å›¾æ‰€ç¤º 1
![](ref/lect2/roll_example2.png)
P(M = 1 | B) = 0:è“è‰²æ˜¯ M=1,çº¢è‰²æ˜¯B

å¦‚å›¾æ‰€ç¤º 2
![](ref/lect2/roll_example3.png)
å¯¹äº$\displaystyle P(M=3|B) =  \frac{2}{5}$
äº‹ä»¶Bå‘ç”Ÿåœ¨5å—æ­£æ–¹å½¢ï¼Œä¸M=3å…±åŒå æ®2å—ã€‚
ä¹Ÿå¯ä»¥ä½¿ç”¨æ¡ä»¶æ¦‚ç‡çš„å®šä¹‰,åˆ†åˆ«è®¡ç®—P(M=3 $\cap$ B) å’Œ P(B)ã€‚

#### Conditional probabilities obey the same axioms

æ‰€æœ‰ä»åŸå§‹æ¦‚ç‡ä¸­æ¨å¯¼å‡ºæ¥çš„å…¬å¼å’Œç†è®ºå¯¹æ¡ä»¶æ¦‚ç‡ä¾ç„¶æœ‰æ•ˆã€‚
æ¡ä»¶æ¦‚ç‡åŒæ ·æ»¡è¶³æ¦‚ç‡çš„å®šç†ã€‚

* P(A | B) $\geq$ 0 éè´Ÿ
* P( $\varOmega$ | B) = 1
* P(N | B) = 1
* $ if \displaystyle A \cap C = \empty, then P(A \cup C | B) = P(A | B) + P(C | B)$
  * $$ \frac{P((A \cup C)\cap B)}{P(B)} = \frac{P(A \cap B) \cup P(C \cap B)}{P(B)} = P(A|B) + P(A | C)
  $$
  * æ­¤æ—¶ä½¿ç”¨äº†ä¸€äº› set theoretic identity(Demorgan's law ä¹Ÿæ˜¯è¿™å…¶ä¸­çš„ç­‰å¼)

#### A radar example: models based on conditional probabilities and three basic tools

åœ¨ä¹‹å‰çš„ä¾‹å­ä¸­ï¼ˆåœ¨äººå£ç»Ÿè®¡ç³»ç»Ÿéšæœºé€‰æ‹©18å²ä»¥ä¸‹ï¼‰ï¼Œå¯ä»¥çœ‹åˆ°æ¡ä»¶æ¦‚ç‡å°†æ–°çš„å·²ç»å‘ç”Ÿçš„ä¿¡æ¯æ·»åŠ åˆ°æ–°çš„æ¨¡å‹ä¹‹ä¸­ï¼Œä»è€Œä¿®æ­£å¾—åˆ°ä¸€ä¸ªæ›´åŠ ç¬¦åˆäº‹å®çš„æ¨¡å‹ã€‚
æ­¤å¤„å°†æŒ‡å‡ºå¦ä¸€ç§ç”¨é€”ä¹Ÿå¯ä»¥é€šè¿‡å€ŸåŠ©æ¡ä»¶æ¦‚ç‡æ„å»ºå¤šé˜¶æ®µçš„å®éªŒæ¨¡å‹ã€‚

å‡è®¾ï¼Œä¸€ä¸ªé›·è¾¾ç³»ç»Ÿç›‘è§†ç©ºä¸­æŸä¸€åŒºåŸŸçš„é£æœºç»è¿‡çš„æƒ…å†µã€‚

* äº‹ä»¶Aï¼šé¢†åŸŸä¹‹ä¸­å‡ºç°äº†é£æœº
* äº‹ä»¶Bï¼šé›·è¾¾æ£€æµ‹åˆ°é£æœºçš„å‡ºç°
å¦‚å›¾æ‰€ç¤ºæ„å»ºæ¨¡å‹
![](ref/lect2/20230704105654.png)
* P(A) = 0.05, $P(A^c) = 0.95$
* P(A | B) = 0.99

1. $P(A \cap B)$
   * P(B | A) = 0.99
   * P(B | A) = $\frac{P(A \cap B)}{P(A)}$
   * P(A \cap B) = P(A) $*$ P(B | A) = 0.99* 0.05

2. P(B)
   * P(B)è¡¨ç¤ºé›·è¾¾çœ‹è§é£è¡Œç‰©çš„äº‹ä»¶æœ‰ä¸¤ç§å¯èƒ½æ€§ï¼š1. ç©ºä¸­å‡ºç°ğŸ›©ï¸ï¼Œé›·è¾¾æ£€æµ‹åˆ°ã€‚2. ç©ºä¸­æ²¡æœ‰ç›‘æµ‹åˆ°é£è¡Œç‰©ï¼Œé›·è¾¾é”™è¯¯åœ°æ£€æµ‹åˆ°å­˜åœ¨ğŸ›©ï¸ã€‚
   * $\displaystyle A \cap B \quad and \quad A^c \cap B, ä¸¤è€…ä¹‹å’Œå°±æ˜¯Bçš„æ¦‚ç‡ã€‚ï¼ˆæ— æ³•ä½¿ç”¨å®šä¹‰å¼å˜å½¢æ¨å¯¼å‡ºP(B),å› ä¸ºæˆ‘ä»¬å¹¶ä¸çŸ¥é“P(A | B)çš„æ¦‚ç‡ã€‚$
   * $0.05 *0.99 + 0.95* 0.10$

3. P(A | B)
   * ç›´æ¥ä½¿ç”¨å®šä¹‰å¼æ¨å¯¼ï¼š$\displaystyle \frac{P(A \cap B)}{P(B)}$

##### The multiplication rule

![](ref/lect2/20230704151922.png)

å¢åŠ äº‹ä»¶C,ç”±å›¾å¯ä»¥çœ‹å‡º

$\displaystyle P(A^c \cap B^c \cap c^c) = P(A^c) *P(B^c | A^c)* P(C^c | A^c \cap B^c)$
ä¸­é—´çš„åˆ†æ”¯è¡¨ç¤ºçš„å°±æ˜¯æ¡ä»¶æ¦‚ç‡

---

ä½¿ç”¨å…¬å¼æ¨å¯¼å¦‚ä¸‹:
$$
P(A | B) = \frac{P(A \cap B)}{P(B)}, P(B|A) = \frac{P(A\cap B)}{P(A)} ;\\
P(A \cap B) = P(B) *P(A | B) = P(A)* P(B | A); \\
\begin{aligned}
P(A^c \cap B^C \cap C^c)
&= P((A^c \cap B^c) \cap P(C^c)) \\
&=P(C^c | (A^c \cap B^c)) *P(A^c \cap B^c) \\
&=P(C^c | (A^c \cap B^c))* P(B^c | A^c) * P(A^c)
\end{aligned}
$$

---

è¿›ä¸€æ­¥æ¨å¹¿
$\displaystyle P(A_1 \cap A_2 \cap A_3 \cap A_4 \cdots A_n) = P(A_1) * P(A_2 | A_1) * P(A_3 | A_1 \cap A_2) * P(A_4 | A_1 \cap A_2 \cap A_3)* \cdots P(A_n | A_1 \cap A_2 \cdots A_{n-1})$
ç®€å†™ä¸º:
$\displaystyle P(A_1) * \prod_{i=2}^{n}P(A_i | A_1 \cap A_2\cap \cdots A_{n-1})$

Exercise:
* $\mathbf{P}(A\cap B\mid C)= \mathbf{P}(A\mid C)\, \mathbf{P}(B\mid A\cap C)$

* å…ˆä½¿ç”¨æ¡ä»¶å˜é‡å®šä¹‰å¼ï¼Œå†ä½¿ç”¨multiplication ruleå°†åˆ†å­éƒ¨åˆ†è½¬åŒ–ï¼Œæœ€åä¼šæ¶ˆæ‰åˆ†æ¯ã€‚
* note: æ¡ä»¶å˜é‡çš„å®šä¹‰å¼åˆ†å­ä¸Šæ˜¯æ‰€æœ‰å‘ç”Ÿäº‹ä»¶çš„äº¤é›†ï¼Œå½“å·²çŸ¥æŸä¸€ä¸ªäº‹ä»¶å·²ç»å‘ç”Ÿæ—¶ï¼Œé™¤è¿™ä¸ªäº‹ä»¶ä¹‹å¤–çš„äº‹ä»¶éƒ½ä¼šè¢«å‰”é™¤æ¨¡å‹ä¹‹ä¸­ï¼Œå¯ä»¥è¿™ä¹ˆè®¤ä¸ºï¼Œæ­¤æ—¶æˆ‘ä»¬æ”¹å˜äº†æ ·æœ¬ç©ºé—´ã€‚

#### Total probability theorem

![](ref/lect2/20230705110420.png)

è¿™ä¸ªä¾‹å­ä¹‹ä¸­æˆ‘ä»¬ä½¿ç”¨äº†*åˆ†è€Œæ²»ä¹‹*çš„æ€æƒ³ï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªæ ·æœ¬ç©ºé—´åˆ†æˆäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼š$A_1 \,A_2 \,A_3$ã€‚æ¯ä¸€ä¸ªéƒ¨åˆ†éƒ½åŒ…å«ä¸€éƒ¨åˆ†çš„äº‹ä»¶Bã€‚
æ­£ä¸­åšæ³•å°†åŸæœ¬çš„å¤§çš„æ ·æœ¬ç©ºé—´åˆ†å‰²çš„æ›´å°ï¼Œä»è€Œç®€åŒ–äº†å¤„ç†â€”â€”å› ä¸ºæˆ‘ä»¬ç°åœ¨å¯ä»¥åœ¨ä¸€ä¸ªæ›´å°çš„ç©ºé—´ï¼ˆ$A_1 \, A_2 \, A_3$ï¼‰ä¹‹ä¸­æ¥æ¢æŸ¥æ¦‚ç‡ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†åˆ«è®¡ç®—å‡º$\mathbf{P}(A_1\cap B), \mathbf{P}(A_2\cap B), \mathbf{P}(A_3\cap B)$,å†å–ä¸‰è€…ä¹‹å’Œï¼Œå³å¯æ±‚Båœ¨æ•´ä¸ªæ ·æœ¬ç©ºé—´å‘ç”Ÿçš„æ¦‚ç‡ã€‚

æ¢å¦ä¸€ç§è§†è§’ï¼Œå¯ä»¥ä»¥æ ‘çš„ç»“æ„æ¥å±•ç¤º,ä¹Ÿå¯ä»¥è¯´æ˜äº‹ä»¶Bå°±æ˜¯ä¸Bç›¸å…³çš„æ ‘çš„å¶å­ç»“ç‚¹æ¦‚ç‡å€¼å’Œã€‚
![](ref/lect2/20230705111549.png)

ç»¼ä¸Šå¯ä»¥å¾—å‡º $\displaystyle \mathbf{P}(B) = \mathbf{P}(A_1\cap B)+\mathbf{P}(A_2\cap B) + \mathbf{P}(A_3\cap B)$

å½“å°†åˆ†åŒºæ”¹ä¸ºæ— é™å¯åºåˆ—åŒ–çš„å½¢å¼ï¼Œä½¿ç”¨Countable add axiomï¼Œå¯ä»¥æ¨å¯¼å‡ºä»¥ä¸‹formulaï¼š
$\displaystyle \mathbf{P}(B) = \sum_{i=1}^{n} \mathbf{P}(A_i\cap B) = \sum_{i=1}^{n} \mathbf{P}(A_i)* \mathbf{P}(B\mid A_i)  $

* $\displaystyle \mathbf{P}(A) = 1$
* æ­¤å…¬å¼æ˜¯$\displaystyle \mathbf{P}(B\mid A_i)$çš„åŠ æƒå¹³å‡å€¼ã€‚
* weightæ˜¯$\displaystyle \mathbf{P}(A_i)$

#### Bayes' rule

**æ•´åˆæ–°è¯æ®çš„å…·ä½“æ–¹æ³•(systematic approach for incorporating new evidence)**
åœ¨Total probability theoremçš„ä¾‹å­ä¹‹ä¸­ï¼Œå°†æ ·æœ¬ç©ºé—´åˆ’åˆ†ä¸ºäº†3ä¸ªåˆ†åŒºã€‚

* å¯¹äºæ¯ä¸€ä¸ªåˆ†åŒºï¼Œ$\displaystyle \mathbf{P}(A_i)$è®¾ç½®ä¸ºä»–çš„ init "beliefs"
* åœ¨å·²ç»å¾—çŸ¥Bå‘ç”Ÿåï¼š$\displaystyle \mathbf{P}(B\mid A_i)å·²çŸ¥$
* åœ¨ç»™å®šBå·²ç»å‘ç”Ÿåï¼Œæ¥è°ƒæ•´init beliefsã€‚

è°ƒæ•´init beliefsï¼š
$$
\begin{aligned}
&\mathbf{P}(A_i\mid B) = \frac{\mathbf{P}(A_i\cap B)}{\mathbf{P}(B)} \\
&åˆ†å­ä½¿ç”¨Mutiple \,Rule \rightarrow \mathbf{P}(B\mid A_i)*\mathbf{P}(A_i) \\
&åˆ†æ¯ä½¿ç”¨Total\, Probibality\, Theorem \Rightarrow \mathbf{P}(A_1 \cap B) + \mathbf{P}(A_2 \cap B) + \cdots + \mathbf{P}(A_n \cap B)
\end{aligned}
$$

ç»¼ä¸Šï¼Œä¿®æ­£beliefsï¼š$\displaystyle \mathbf{P}(A_i\mid B) = \frac{\mathbf{P}(B\mid A_i)*\mathbf{P}(A_i)}{\sum_{j=1}^{\infin}{\mathbf{P}(B\mid A_j)*P(A_j)}}$ï¼Œè¿™ä¹Ÿå°±æ˜¯Bayesâ€™s ruleçš„è®¡ç®—æ–¹æ³•ã€‚

Bayes'rule èƒ½å¤Ÿæ ¹æ®å·²ç»çŸ¥é“çš„äº‹ä»¶æ¦‚ç‡å»æ¨æµ‹å¦ä¸€ä¸ªäº‹ä»¶çš„æ¦‚ç‡$\displaystyle \mathbf{P}(A_i\mid B) \longleftrightarrow \mathbf{P}(B | A_i)$
